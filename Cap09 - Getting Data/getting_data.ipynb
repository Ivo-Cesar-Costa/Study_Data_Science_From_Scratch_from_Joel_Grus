{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee931b39-baf0-4348-9dc8-3a08aa80bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just stick some data there\n",
    "with open('email_addresses.txt', 'w') as f:\n",
    "    f.write(\"joelgrus@gmail.com\\n\")\n",
    "    f.write(\"joel@m.datasciencester.com\\n\")\n",
    "    f.write(\"joelgrus@m.datasciencester.com\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be133eb-8cfc-4309-8cd5-36efb2dc6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joelgrus@gmail.com\n",
      "joel@m.datasciencester.com\n",
      "joelgrus@m.datasciencester.com\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('email_addresses.txt', \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c4aa07-bfc3-4e32-bbb5-dd7329be634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(email_address: str) -> str:\n",
    "    \"\"\"Split on '@' and return the last piece\"\"\"\n",
    "    return email_address.lower().split(\"@\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09080f3d-a6b4-4fd7-b83e-370109f6c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a couple of tests\n",
    "assert get_domain('joelgrus@gmail.com') == 'gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d39b09-0c37-4f56-a3d8-7232c3039b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_domain('joel@m.datasciencester.com') == 'm.datasciencester.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb10a9d-0280-4557-8958-c359f7b87500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98dd73ab-8591-4d2b-8fed-121dd1014028",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('email_addresses.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip())\n",
    "                            for line in f\n",
    "                            if \"@\" in line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43463567-68ef-42a9-8903-83a3da857bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'gmail.com': 1, 'm.datasciencester.com': 2})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e20ae64-a001-4321-9ab4-9b30d4138d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tab_delimited_stock_prices.txt', 'w') as f:\n",
    "    f.write(\"\"\"6/20/2014\\tAAPL\\t90.91\n",
    "6/20/2014\\tMSFT\\t41.68\n",
    "6/20/2014\\tFB\\t64.5\n",
    "6/19/2014\\tAAPL\\t91.86\n",
    "6/19/2014\\tMSFT\\t41.51\n",
    "6/19/2014\\tFB\\t64.34\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d556f9-4269-41db-a80f-536683cb9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20/2014\tAAPL\t90.91\n",
      "6/20/2014\tMSFT\t41.68\n",
      "6/20/2014\tFB\t64.5\n",
      "6/19/2014\tAAPL\t91.86\n",
      "6/19/2014\tMSFT\t41.51\n",
      "6/19/2014\tFB\t64.34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('tab_delimited_stock_prices.txt', \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aca58ae-a533-4d9c-9949-50ecb444afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(date: str, symbol: str, closing_price: float) -> None:\n",
    "    # Imaginge that this function actually does something.\n",
    "    assert closing_price > 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6725b5-d338-4188-8d9e-4876e48c5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('tab_delimited_stock_prices.txt') as f:\n",
    "    tab_reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in tab_reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        process(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5959320c-a818-4ccf-bc64-e4522034883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('colon_delimited_stock_prices.txt', 'w') as f:\n",
    "    f.write(\"\"\"date:symbol:closing_price\n",
    "6/20/2014:AAPL:90.91\n",
    "6/20/2014:MSFT:41.68\n",
    "6/20/2014:FB:64.5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f7ba85f-6ce2-4053-90d2-35d6960d05b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date:symbol:closing_price\n",
      "6/20/2014:AAPL:90.91\n",
      "6/20/2014:MSFT:41.68\n",
      "6/20/2014:FB:64.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('colon_delimited_stock_prices.txt', \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c5bdbde-b033-4cbf-9bfc-af3c5719b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('colon_delimited_stock_prices.txt') as f:\n",
    "    colon_reader = csv.DictReader(f, delimiter=':')\n",
    "    for dict_row in colon_reader:\n",
    "        date = dict_row[\"date\"]\n",
    "        symbol = dict_row[\"symbol\"]\n",
    "        closing_price = float(dict_row[\"closing_price\"])\n",
    "        process(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7721cf0a-a494-43d8-b245-9fe071e36617",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_prices = {'AAPL': 90.91, 'MSFT': 41.68, 'FB': 64.5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3106732d-f173-4bbc-bf7a-64c502fc91aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comma_delimited_stock_prices.txt', 'w') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in todays_prices.items():\n",
    "        csv_writer.writerow([stock, price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "012b71bb-a2f1-4aaa-91b4-c78b67e91d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL,90.91\n",
      "\n",
      "MSFT,41.68\n",
      "\n",
      "FB,64.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('comma_delimited_stock_prices.txt', \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f01512a-ee3a-4afa-a8e0-c4eb44ff9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[\"test1\", \"success\", \"Monday\"],\n",
    "           [\"test2\", \"success, kind of\", \"Tuesday\"],\n",
    "           [\"test3\", \"failure, kind of\", \"Wednesday\"],\n",
    "           [\"test4\", \"failure, utter\", \"Thursday\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b815f94f-6b9b-4cff-85da-abebe785c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't do this!\n",
    "with open('bad_csv.txt', 'w') as f:\n",
    "    for row in results:\n",
    "        f.write(\",\".join(map(str, row))) # might have too many commas in it!\n",
    "        f.write(\"\\n\")                    # row might have newlines as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a182a370-376c-4598-888e-0cab1ed0afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1,success,Monday\n",
      "test2,success, kind of,Tuesday\n",
      "test3,failure, kind of,Wednesday\n",
      "test4,failure, utter,Thursday\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('bad_csv.txt', \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f27a240-0144-4e4c-b1f5-e52b20b0811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "740a5c5b-38d5-41c2-8e32-71202ff2eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I put the relevant HTML file on GitHub. In order to fit\n",
    "# the URL in the book I had to split it across two lines.\n",
    "# Recall that whitespace-separated strings get concatenated.\n",
    "url = (\"https://raw.githubusercontent.com/\"\n",
    "       \"joelgrus/data/master/getting-data.html\")\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "first_paragraph = soup.find('p')        # or just soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76bb1067-19fc-46d3-af08-3d2b1a156e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en-US\"><head>\n",
       "    <title>Getting Data</title>\n",
       "    <meta charset=\"utf-8\"/>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Getting Data</h1>\n",
       "    <div class=\"explanation\">\n",
       "        This is an explanation.\n",
       "    </div>\n",
       "    <div class=\"comment\">\n",
       "        This is a comment.\n",
       "    </div>\n",
       "    <div class=\"content\">\n",
       "        <p id=\"p1\">This is the first paragraph.</p>\n",
       "        <p class=\"important\">This is the second paragraph.</p>\n",
       "    </div>\n",
       "    <div class=\"signature\">\n",
       "        <span id=\"name\">Joel</span>\n",
       "        <span id=\"twitter\">@joelgrus</span>\n",
       "        <span id=\"email\">joelgrus-at-gmail</span>\n",
       "    </div>\n",
       "\n",
       "\n",
       "</body></html>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a826b376-adbb-4904-9fa8-5bc6e1279aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"p1\">This is the first paragraph.</p>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17779b96-ba6b-4ee1-811f-070d41f26c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f3a1d48-e201-49f3-b1f2-7ba59869429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert str(soup.find('p')) == '<p id=\"p1\">This is the first paragraph.</p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a4dab6c-02ba-4d32-9fc8-c3be6dfab0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_words = soup.p.text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f44bf58c-edfa-4643-a315-3083ff9d27ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the first paragraph.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "188743a4-48a4-4cd0-be15-8641fb375c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'the', 'first', 'paragraph.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "032f00d6-a666-43c2-b23a-34be089f3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert first_paragraph_words == ['This', 'is', 'the', 'first', 'paragraph.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "824852f1-1bc3-4fb0-abd3-e783bd9baa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_paragraph_id = soup.p['id']       # raises KeyError if no 'id'\n",
    "first_paragraph_id2 = soup.p.get('id')  # returns None if no 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8b82434-9d1f-4f7c-a7ca-9736db070c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19f3fe88-0dfd-4538-bd18-572843084d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88817ffe-fea8-4738-a586-790a97fdbf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert first_paragraph_id == first_paragraph_id2 == 'p1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de7d2dc7-b0e0-4e2b-b029-ea2551d6fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paragraphs = soup.find_all('p')  # or just soup('p')\n",
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1632e310-6048-461b-825a-70ffc28bb288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"p1\">This is the first paragraph.</p>,\n",
       " <p class=\"important\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a288a05-ba36-4f63-be7f-808ebc0897eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"p1\">This is the first paragraph.</p>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_with_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "866a04a5-06ae-4825-b1bd-7c5cb2aeb445",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_paragraphs) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "804b8d03-d1d6-4d4b-8de0-ba529080e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(paragraphs_with_ids) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a7efaf7-74b5-4213-ba3f-61adf010b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_paragraphs = soup('p', {'class' : 'important'})\n",
    "important_paragraphs2 = soup('p', 'important')\n",
    "important_paragraphs3 = [p for p in soup('p')\n",
    "                         if 'important' in p.get('class', [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80a83230-74f4-4095-94f9-cd9596bfae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"important\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2282a224-8384-4295-9a46-2294bf3a538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"important\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_paragraphs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e44db192-7d56-4738-a8a1-6417d5c4f307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"important\">This is the second paragraph.</p>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_paragraphs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7873335-4aca-4d03-9f89-54a680835ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert important_paragraphs == important_paragraphs2 == important_paragraphs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad9523a5-5c1a-4a77-9127-db2e8fee2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(important_paragraphs) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f3ee4e-c368-4482-a9bd-690a082c7300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"explanation\">\n",
       "         This is an explanation.\n",
       "     </div>,\n",
       " <div class=\"comment\">\n",
       "         This is a comment.\n",
       "     </div>,\n",
       " <div class=\"content\">\n",
       "         <p id=\"p1\">This is the first paragraph.</p>\n",
       "         <p class=\"important\">This is the second paragraph.</p>\n",
       "     </div>,\n",
       " <div class=\"signature\">\n",
       "         <span id=\"name\">Joel</span>\n",
       "         <span id=\"twitter\">@joelgrus</span>\n",
       "         <span id=\"email\">joelgrus-at-gmail</span>\n",
       "     </div>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a3c9e2e-137f-4c76-b642-d674adb05cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning, will return the same span multiple times\n",
    "# if it sits inside multiple divs\n",
    "# be more clever if that's the case\n",
    "spans_inside_divs = [span\n",
    "                     for div in soup('div')     # for each <div> on the page\n",
    "                     for span in div('span')]   # find each <span> inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31e451c2-b03a-4a32-a7fc-ab0525a5cad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span id=\"name\">Joel</span>,\n",
       " <span id=\"twitter\">@joelgrus</span>,\n",
       " <span id=\"email\">joelgrus-at-gmail</span>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_inside_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df98e76a-1c98-42c3-80d4-c9ab71d09a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(spans_inside_divs) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a5dd386-ce62-47e7-b3ac-43a97d7e059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraph_mentions(text: str, keyword: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if a <p> inside the text mentions {keyword}\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text, 'html5lib')\n",
    "    paragraphs = [p.get_text() for p in soup('p')]\n",
    "\n",
    "    return any(keyword.lower() in paragraph.lower()\n",
    "               for paragraph in paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "726aa24c-55e5-4573-a95a-fbb0420c194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body><h1>Facebook</h1><p>Twitter</p></body></html>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"<body><h1>Facebook</h1><p>Twitter</p>\"\"\"\n",
    "soup = BeautifulSoup(text, 'html5lib')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd43f76d-38c9-48d7-b3d6-5d343b7a67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert paragraph_mentions(text, \"twitter\")       # is inside a <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d645b2c6-1edb-4d87-9fb8-6a7773c00e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not paragraph_mentions(text, \"facebook\")  # not inside a <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26c3fcde-1ed7-4c97-bc85-bebe76d85d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Data Science Book',\n",
       " 'author': 'Joel Grus',\n",
       " 'publicationYear': 2019,\n",
       " 'topics': ['data', 'science', 'data science']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ \"title\" : \"Data Science Book\",\n",
    "  \"author\" : \"Joel Grus\",\n",
    "  \"publicationYear\" : 2019,\n",
    "  \"topics\" : [ \"data\", \"science\", \"data science\"] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e4ab50b-12a3-4eae-b88f-b966d97bfeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "                  \"author\" : \"Joel Grus\",\n",
    "                  \"publicationYear\" : 2019,\n",
    "                  \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "719abf3f-bc51-4cda-8daf-3c06bc243c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Data Science Book', 'author': 'Joel Grus', 'publicationYear': 2019, 'topics': ['data', 'science', 'data science']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the JSON to create a Python dict\n",
    "deserialized = json.loads(serialized)\n",
    "print(deserialized)\n",
    "type(deserialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8a67adf-183e-455e-b41b-1c717cfbb278",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert deserialized[\"publicationYear\"] == 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ee11a98-566d-4518-b7da-d8c725d93bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"data science\" in deserialized[\"topics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d634daf-a2bd-4600-8ce1-23fa5c225804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    \n",
    "    url = \"https://www.house.gov/representatives\"\n",
    "    text = requests.get(url).text\n",
    "    soup = BeautifulSoup(text, \"html5lib\")\n",
    "    \n",
    "    all_urls = [a['href']\n",
    "                for a in soup('a')\n",
    "                if a.has_attr('href')]\n",
    "    \n",
    "    print(len(all_urls))  # 965 for me, way too many\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    # Must start with http:// or https://\n",
    "    # Must end with .house.gov or .house.gov/\n",
    "    regex = r\"^https?://.*\\.house\\.gov/?$\"\n",
    "    \n",
    "    # Let's write some tests!\n",
    "    assert re.match(regex, \"http://joel.house.gov\")\n",
    "    assert re.match(regex, \"https://joel.house.gov\")\n",
    "    assert re.match(regex, \"http://joel.house.gov/\")\n",
    "    assert re.match(regex, \"https://joel.house.gov/\")\n",
    "    assert not re.match(regex, \"joel.house.gov\")\n",
    "    assert not re.match(regex, \"http://joel.house.com\")\n",
    "    assert not re.match(regex, \"https://joel.house.gov/biography\")\n",
    "    \n",
    "    # And now apply\n",
    "    good_urls = [url for url in all_urls if re.match(regex, url)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dac06396-c61e-4b87-878e-d2996dfcdeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.house.gov/representatives\"\n",
    "text = requests.get(url).text\n",
    "soup = BeautifulSoup(text, \"html5lib\")\n",
    "    \n",
    "all_urls = [a['href']\n",
    "            for a in soup('a')\n",
    "            if a.has_attr('href')]\n",
    "    \n",
    "print(len(all_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89cc221e-b010-416a-9f03-727bd0b5e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "    \n",
    "# Must start with http:// or https://\n",
    "# Must end with .house.gov or .house.gov/\n",
    "regex = r\"^https?://.*\\.house\\.gov/?$\"\n",
    "    \n",
    "# Let's write some tests!\n",
    "assert re.match(regex, \"http://joel.house.gov\")\n",
    "assert re.match(regex, \"https://joel.house.gov\")\n",
    "assert re.match(regex, \"http://joel.house.gov/\")\n",
    "assert re.match(regex, \"https://joel.house.gov/\")\n",
    "assert not re.match(regex, \"joel.house.gov\")\n",
    "assert not re.match(regex, \"http://joel.house.com\")\n",
    "assert not re.match(regex, \"https://joel.house.gov/biography\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84146526-4355-407d-bb32-b5eb1fe7dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878\n"
     ]
    }
   ],
   "source": [
    "# And now apply\n",
    "good_urls = [url for url in all_urls if re.match(regex, url)]\n",
    "    \n",
    "print(len(good_urls))  # still 862 for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97a18042-29f4-4a2a-b966-fff4d3398841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_original_good_urls = len(good_urls)\n",
    "num_original_good_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "671965ef-cc8b-4c27-b379-d2291025fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://james.house.gov',\n",
       " 'https://dustyjohnson.house.gov/',\n",
       " 'https://vanduyne.house.gov']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_urls = list(set(good_urls))\n",
    "good_urls[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08fa3457-0cda-4ba3-84e4-5d70292b38ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n"
     ]
    }
   ],
   "source": [
    "print(len(good_urls))  # only 431 for me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a767f6d8-462b-4f63-9357-89012646dd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(good_urls) < num_original_good_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfa8ed9c-9c98-4c22-b6ef-17561794cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://jayapal.house.gov').text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71bf6e3a-9da6-4dd4-8bc5-5d3230391dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://jayapal.house.gov/category/news/',\n",
       " 'https://jayapal.house.gov/category/press-releases/'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a set because the links might appear multiple times.\n",
    "links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d439ae3-2a7b-46c5-8a22-461322da70f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://jayapal.house.gov/category/news/', 'https://jayapal.house.gov/category/press-releases/'}\n"
     ]
    }
   ],
   "source": [
    "print(links) # {'/media/press-releases'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb068a1a-7cfa-4289-bf14-c26ce274aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after sampling, left with ['https://babin.house.gov', 'https://sessions.house.gov', 'https://finstad.house.gov/', 'https://strong.house.gov', 'https://takano.house.gov']\n"
     ]
    }
   ],
   "source": [
    "# I don't want this file to scrape all 400+ websites every time it runs.\n",
    "# So I'm going to randomly throw out most of the urls.\n",
    "# The code in the book doesn't do this.\n",
    "import random\n",
    "good_urls = random.sample(good_urls, 5)\n",
    "print(f\"after sampling, left with {good_urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b21da744-680e-443e-aa1b-6b95036c2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4d38467-7b0d-4011-9fe0-7eb0e61eb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_releases: Dict[str, Set[str]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "08397867-7c7d-4b47-929e-994dae2190b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://babin.house.gov: {'/news/documentquery.aspx?DocumentTypeID=27'}\n",
      "https://sessions.house.gov: {'/press-releases'}\n",
      "https://finstad.house.gov/: {'/press-releases'}\n",
      "https://strong.house.gov: {'/media/press-releases'}\n",
      "https://takano.house.gov: {'https://takano.house.gov/newsroom/press-releases'}\n"
     ]
    }
   ],
   "source": [
    "for house_url in good_urls:\n",
    "    html = requests.get(house_url).text\n",
    "    soup = BeautifulSoup(html, 'html5lib')\n",
    "    pr_links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "    print(f\"{house_url}: {pr_links}\")\n",
    "    press_releases[house_url] = pr_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "23e759b4-0816-4136-8221-b67643da4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "for house_url, pr_links in press_releases.items():\n",
    "    for pr_link in pr_links:\n",
    "        url = f\"{house_url}/{pr_link}\"\n",
    "        text = requests.get(url).text\n",
    "    \n",
    "        if paragraph_mentions(text, 'data'):\n",
    "            print(f\"{house_url}\")\n",
    "            break  # done with this house_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f718022a-fe05-43df-a82e-de088482cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "    \n",
    "github_user = \"joelgrus\"\n",
    "endpoint = f\"https://api.github.com/users/{github_user}/repos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8fb5777e-3f37-41af-bf7c-8ba216eb2b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-11-30T22:41:16Z'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos = json.loads(requests.get(endpoint).text)\n",
    "repos[1][\"created_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1ec6c32-3f20-48f1-8c75-0dbc7f5ad31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f0c3416d-6f2c-4ef2-bcdb-5ee2e4cc5c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2017, 12, 2, 20, 13, 49, tzinfo=tzutc()),\n",
       " datetime.datetime(2018, 11, 30, 22, 41, 16, tzinfo=tzutc()),\n",
       " datetime.datetime(2019, 12, 1, 2, 57, 18, tzinfo=tzutc())]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "dates[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7b492e59-bf5a-45f1-8fe4-73888bb9ca70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({12: 4, 11: 8, 2: 2, 1: 2, 9: 5, 7: 3, 5: 2, 6: 1, 8: 2, 4: 1})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_counts = Counter(date.month for date in dates)\n",
    "month_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43cb0d45-d52d-41e8-8298-7ec832e0401b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 5, 4: 6, 6: 4, 2: 8, 1: 6, 3: 1})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday_counts = Counter(date.weekday() for date in dates)\n",
    "weekday_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e89428ce-8ced-4538-8ffc-92a0934fbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_5_repositories = sorted(repos,\n",
    "                                 key=lambda r: r[\"pushed_at\"],\n",
    "                                 reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "038e3c4d-914e-4b97-9321-a8f3155e8f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5_repositories[1][\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a83c9ec9-f288-4afe-bd87-62e9c730c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_5_languages = [repo[\"language\"]\n",
    "                        for repo in last_5_repositories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ff1273e-2e9c-408a-b14a-4c6cb94b3c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JavaScript', 'Python', 'Python', 'Python', 'Python']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "420b6fb0-3027-4254-b75c-eda92ba9cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "    \n",
    "# # Feel free to plug your key and secret in directly\n",
    "# CONSUMER_KEY = os.environ.get(\"TWITTER_CONSUMER_KEY\")\n",
    "# CONSUMER_SECRET = os.environ.get(\"TWITTER_CONSUMER_SECRET\")\n",
    "    \n",
    "# import webbrowser\n",
    "# from twython import Twython\n",
    "    \n",
    "# # Get a temporary client to retrieve an authentication url\n",
    "# temp_client = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "# temp_creds = temp_client.get_authentication_tokens()\n",
    "# url = temp_creds['auth_url']\n",
    "    \n",
    "# # Now visit that URL to authorize the application and get a PIN\n",
    "# print(f\"go visit {url} and get the PIN code and paste it below\")\n",
    "# webbrowser.open(url)\n",
    "# PIN_CODE = input(\"please enter the PIN code: \")\n",
    "    \n",
    "# # Now we use that PIN_CODE to get the actual tokens\n",
    "# auth_client = Twython(CONSUMER_KEY,\n",
    "#                         CONSUMER_SECRET,\n",
    "#                         temp_creds['oauth_token'],\n",
    "#                         temp_creds['oauth_token_secret'])\n",
    "# final_step = auth_client.get_authorized_tokens(PIN_CODE)\n",
    "# ACCESS_TOKEN = final_step['oauth_token']\n",
    "# ACCESS_TOKEN_SECRET = final_step['oauth_token_secret']\n",
    "    \n",
    "# # And get a new Twython instance using them.\n",
    "# twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    \n",
    "# from twython import TwythonStreamer\n",
    "    \n",
    "# # Appending data to a global variable is pretty poor form\n",
    "# # but it makes the example much simpler\n",
    "# tweets = []\n",
    "    \n",
    "# class MyStreamer(TwythonStreamer):\n",
    "#     def on_success(self, data):\n",
    "#         \"\"\"\n",
    "#         What do we do when twitter sends us data?\n",
    "#         Here data will be a Python dict representing a tweet\n",
    "#         \"\"\"\n",
    "#         # We only want to collect English-language tweets\n",
    "#         if data.get('lang') == 'en':\n",
    "#             tweets.append(data)\n",
    "#             print(f\"received tweet #{len(tweets)}\")\n",
    "    \n",
    "#         # Stop when we've collected enough\n",
    "#         if len(tweets) >= 100:\n",
    "#             self.disconnect()\n",
    "    \n",
    "#     def on_error(self, status_code, data):\n",
    "#         print(status_code, data)\n",
    "#         self.disconnect()\n",
    "    \n",
    "# stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET,\n",
    "#                     ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    \n",
    "# # starts consuming public statuses that contain the keyword 'data'\n",
    "# stream.statuses.filter(track='data')\n",
    "    \n",
    "# # if instead we wanted to start consuming a sample of *all* public statuses\n",
    "# # stream.statuses.sample()\n",
    "    \n",
    "# if __name__ == \"__main__\": main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
