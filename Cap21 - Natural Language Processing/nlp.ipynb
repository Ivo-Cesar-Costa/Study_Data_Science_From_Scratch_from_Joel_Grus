{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a944f0-8fe3-406b-b297-3219acd7558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.gca().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649bf563-5493-449a-9d04-17172da36bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ (\"big data\", 100, 15), (\"Hadoop\", 95, 25), (\"Python\", 75, 50),\n",
    "         (\"R\", 50, 40), (\"machine learning\", 80, 20), (\"statistics\", 20, 60),\n",
    "         (\"data science\", 60, 70), (\"analytics\", 90, 3),\n",
    "         (\"team player\", 85, 85), (\"dynamic\", 2, 90), (\"synergies\", 70, 0),\n",
    "         (\"actionable insights\", 40, 30), (\"think out of the box\", 45, 10),\n",
    "         (\"self-starter\", 30, 50), (\"customer focus\", 65, 15),\n",
    "         (\"thought leadership\", 35, 35)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5067a764-3ff5-483f-a86c-47b4d5ea74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85a8cf64-517d-48c5-a6eb-eb545476cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_unicode(text: str) -> str:\n",
    "    return text.replace(u\"\\u2019\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2972e584-9fb8-49ad-bb56-1b6597f5ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4690b6e4-59f0-4596-be1d-53a77c8cd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.oreilly.com/ideas/what-is-data-science\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f882d1d-31c4-445b-a29b-bbdd5ab668c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find(\"div\", \"article-body\")   # find article-body div\n",
    "regex = r\"[\\w']+|[\\.]\"                       # matches a word or a period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922465bc-cc63-41bd-b963-13e84c40b15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d927c480-a4c7-4bdb-81b1-4a3ce34e4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ebf2155-2c9e-42d7-97fd-2e335264a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for paragraph in content(\"p\"):\n",
    "#     words = re.findall(regex, fix_unicode(paragraph.text))\n",
    "#     document.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3adda03-6479-414c-a3dd-448b3e3603ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in soup.find(\"p\"):\n",
    "    words = re.findall(regex, fix_unicode(paragraph.text))\n",
    "    document.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4896834e-3a65-4b42-bdce-533683964c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'future',\n",
       " 'belongs',\n",
       " 'to',\n",
       " 'the',\n",
       " 'companies',\n",
       " 'and',\n",
       " 'people',\n",
       " 'that',\n",
       " 'turn',\n",
       " 'data',\n",
       " 'into',\n",
       " 'products',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb307458-0153-4ff8-ae61-10d83e8615c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3fdc1a9-3c46-4565-943f-e85381c95178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions = defaultdict(list)\n",
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595533c6-c63f-49ab-9b45-4102d6b95c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prev, current in zip(document, document[1:]):\n",
    "    transitions[prev].append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c67e363-bb36-4f7d-84dd-39bb576e37e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'The': ['future'],\n",
       "             'future': ['belongs'],\n",
       "             'belongs': ['to'],\n",
       "             'to': ['the'],\n",
       "             'the': ['companies'],\n",
       "             'companies': ['and'],\n",
       "             'and': ['people'],\n",
       "             'people': ['that'],\n",
       "             'that': ['turn'],\n",
       "             'turn': ['data'],\n",
       "             'data': ['into'],\n",
       "             'into': ['products'],\n",
       "             'products': ['.']})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbcf279e-3a5f-45b1-90dd-ad768d86d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_bigrams() -> str:\n",
    "    current = \".\"   # this means the next word will start a sentence\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]    # bigrams (current, _)\n",
    "        current = random.choice(next_word_candidates)  # choose one at random\n",
    "        result.append(current)                         # append it to results\n",
    "        if current == \".\": return \" \".join(result)     # if \".\" we're done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4664adf3-49f5-4f06-b987-b0dc79c523d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_transitions = defaultdict(list)\n",
    "trigram_transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea970d20-a0eb-4305-a4d9-ae443d813f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5dd0e0-f4d0-4633-9bac-02fa1b6cbd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prev, current, next in zip(document, document[1:], document[2:]):\n",
    "\n",
    "    if prev == \".\":              # if the previous \"word\" was a period\n",
    "        starts.append(current)   # then this is a start word\n",
    "\n",
    "    trigram_transitions[(prev, current)].append(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40e4f4ef-09e5-416b-b4cc-896cf6422781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_trigrams() -> str:\n",
    "    current = random.choice(starts)   # choose a random starting word\n",
    "    prev = \".\"                        # and precede it with a '.'\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transitions[(prev, current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "\n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d3937b1-701f-4a5e-a9b2-cb5527250059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82fa696d-abc5-4da6-80ca-f243dda82dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Dict[str, typing.List[str]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type alias to refer to grammars later\n",
    "Grammar = Dict[str, List[str]]\n",
    "Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6b48466-d77c-4c38-80f3-0ea888e01def",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = {\n",
    "    \"_S\"  : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_N\",\n",
    "             \"_A _NP _P _A _N\"],\n",
    "    \"_VP\" : [\"_V\",\n",
    "             \"_V _NP\"],\n",
    "    \"_N\"  : [\"data science\", \"Python\", \"regression\"],\n",
    "    \"_A\"  : [\"big\", \"linear\", \"logistic\"],\n",
    "    \"_P\"  : [\"about\", \"near\"],\n",
    "    \"_V\"  : [\"learns\", \"trains\", \"tests\", \"is\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd1c7fa7-4e02-401d-bd09-4cf78be2b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(token: str) -> bool:\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "761d7d6f-9da7-40e2-bd79-d295d3428d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(grammar: Grammar, tokens: List[str]) -> List[str]:\n",
    "    for i, token in enumerate(tokens):\n",
    "        # If this is a terminal token, skip it.\n",
    "        if is_terminal(token): continue\n",
    "\n",
    "        # Otherwise, it's a non-terminal token,\n",
    "        # so we need to choose a replacement at random.\n",
    "        replacement = random.choice(grammar[token])\n",
    "\n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            # Replacement could be e.g. \"_NP _VP\", so we need to\n",
    "            # split it on spaces and splice it in.\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "\n",
    "        # Now call expand on the new list of tokens.\n",
    "        return expand(grammar, tokens)\n",
    "\n",
    "    # If we get here we had all terminals and are done\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8f6a5c9-a0eb-428f-9ba5-848bdfdf85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammar: Grammar) -> List[str]:\n",
    "    return expand(grammar, [\"_S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c18136f-1fd0-45a2-99f5-aca57c31521f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_S': ['_NP _VP'],\n",
       " '_NP': ['_N', '_A _NP _P _A _N'],\n",
       " '_VP': ['_V', '_V _NP'],\n",
       " '_N': ['data science', 'Python', 'regression'],\n",
       " '_A': ['big', 'linear', 'logistic'],\n",
       " '_P': ['about', 'near'],\n",
       " '_V': ['learns', 'trains', 'tests', 'is']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6b380a2-9a8f-468a-b3f7-6127afb686b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7793bc42-f422-49fc-96dc-9c7aaf4c7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_a_die() -> int:\n",
    "    return random.choice([1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f222ffb-8d9d-4542-b689-8f6a1837bd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roll_a_die()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b811048d-b591-46c7-b16c-21f519ca325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_sample() -> Tuple[int, int]:\n",
    "    d1 = roll_a_die()\n",
    "    d2 = roll_a_die()\n",
    "    return d1, d1 + d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d135d495-35b8-4f92-9331-73c30388e1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "468da019-a6c8-4792-b870-5d238d5e0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_y_given_x(x: int) -> int:\n",
    "    \"\"\"equally likely to be x + 1, x + 2, ... , x + 6\"\"\"\n",
    "    return x + roll_a_die()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f391186-0d6a-486c-867f-98d8f5c564b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_y_given_x(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f2dd5ba-7be5-4bce-b98a-1ea7bb5ea76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_x_given_y(y: int) -> int:\n",
    "    if y <= 7:\n",
    "        # if the total is 7 or less, the first die is equally likely to be\n",
    "        # 1, 2, ..., (total - 1)\n",
    "        return random.randrange(1, y)\n",
    "    else:\n",
    "        # if the total is 7 or more, the first die is equally likely to be\n",
    "        # (total - 6), (total - 5), ..., 6\n",
    "        return random.randrange(y - 6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf8d0895-fbbe-4c29-b317-9d4e804283b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_x_given_y(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acc5eb68-a7b0-42d3-b60e-5841b01479ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sample(num_iters: int = 100) -> Tuple[int, int]:\n",
    "    x, y = 1, 2 # doesn't really matter\n",
    "    for _ in range(num_iters):\n",
    "        x = random_x_given_y(y)\n",
    "        y = random_y_given_x(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb67d48f-38d2-4544-bf73-46b0c4ba95f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gibbs_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b87deec1-7c59-4588-8eae-12bcf825235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(num_samples: int = 1000) -> Dict[int, List[int]]:\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for _ in range(num_samples):\n",
    "        counts[gibbs_sample()][0] += 1\n",
    "        counts[direct_sample()][1] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dc620d4-108a-41c1-87ad-3b2dfdc97a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from(weights: List[float]) -> int:\n",
    "    \"\"\"returns i with probability weights[i] / sum(weights)\"\"\"\n",
    "    total = sum(weights)\n",
    "    rnd = total * random.random()      # uniform between 0 and total\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w                       # return the smallest i such that\n",
    "        if rnd <= 0: return i          # weights[0] + ... + weights[i] >= rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a9f4f89-d66a-4fe2-a4c2-15bce830b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "627b51cc-ce5e-44ce-ace9-ae882a1d9d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 781, 1: 107, 0: 112})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw 1000 times and count\n",
    "draws = Counter(sample_from([0.1, 0.1, 0.8]) for _ in range(1000))\n",
    "draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f273d80-fddd-419a-b618-ff2698e8f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 10 < draws[0] < 190   # should be ~10%, this is a really loose test\n",
    "assert 10 < draws[1] < 190   # should be ~10%, this is a really loose test\n",
    "assert 650 < draws[2] < 950  # should be ~80%, this is a really loose test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b407a5e7-c446-498d-898c-81d908fa5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert draws[0] + draws[1] + draws[2] == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ebe547e-f2df-4ed7-8b05-12d930cdf2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "086979af-174b-42c5-8da2-af4c3a065e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "176c0439-2135-4ebf-874a-f89f582e137d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter(),\n",
       " Counter()]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of Counters, one for each document\n",
    "document_topic_counts = [Counter() for _ in documents]\n",
    "document_topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec6d461f-ae1e-49ab-8ccc-43e5b602c51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter(), Counter(), Counter(), Counter()]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of Counters, one for each topic\n",
    "topic_word_counts = [Counter() for _ in range(K)]\n",
    "topic_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65fbe052-32df-4d34-8c0d-52a5d85a2838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of numbers, one for each topic\n",
    "topic_counts = [0 for _ in range(K)]\n",
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4784ccac-fc5f-4217-ad4e-ecbf156bee39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 5, 6, 5, 4, 6, 4, 4, 4, 4, 3, 4, 3, 5, 3]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of numbers, one for each document\n",
    "document_lengths = [len(document) for document in documents]\n",
    "document_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f520bb01-461a-45c3-989b-43a07915cfb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Big Data',\n",
       " 'C++',\n",
       " 'Cassandra',\n",
       " 'HBase',\n",
       " 'Hadoop',\n",
       " 'Haskell',\n",
       " 'Java',\n",
       " 'Mahout',\n",
       " 'MapReduce',\n",
       " 'MongoDB',\n",
       " 'MySQL',\n",
       " 'NoSQL',\n",
       " 'Postgres',\n",
       " 'Python',\n",
       " 'R',\n",
       " 'Spark',\n",
       " 'Storm',\n",
       " 'artificial intelligence',\n",
       " 'databases',\n",
       " 'decision trees',\n",
       " 'deep learning',\n",
       " 'libsvm',\n",
       " 'machine learning',\n",
       " 'mathematics',\n",
       " 'neural networks',\n",
       " 'numpy',\n",
       " 'pandas',\n",
       " 'probability',\n",
       " 'programming languages',\n",
       " 'regression',\n",
       " 'scikit-learn',\n",
       " 'scipy',\n",
       " 'statistics',\n",
       " 'statsmodels',\n",
       " 'support vector machines',\n",
       " 'theory'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_words = set(word for document in documents for word in document)\n",
    "distinct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a1cb6f3-8a9d-483c-836e-9fce4a766351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = len(distinct_words)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae81a877-34c9-4dc0-aa59-bd0334323c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = len(documents)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbb89578-3b8c-4f87-b985-3ee2e24a0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_topic_given_document(topic: int, d: int, alpha: float = 0.1) -> float:\n",
    "    \"\"\"\n",
    "    The fraction of words in document _d_\n",
    "    that are assigned to _topic_ (plus some smoothing)\n",
    "    \"\"\"\n",
    "    return ((document_topic_counts[d][topic] + alpha) /\n",
    "            (document_lengths[d] + K * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbae1b56-b23e-4261-a275-1e297b4364f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_word_given_topic(word: str, topic: int, beta: float = 0.1) -> float:\n",
    "    \"\"\"\n",
    "    The fraction of words assigned to _topic_\n",
    "    that equal _word_ (plus some smoothing)\n",
    "    \"\"\"\n",
    "    return ((topic_word_counts[topic][word] + beta) /\n",
    "            (topic_counts[topic] + W * beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b660983-86ae-4104-8d04-fb4735963dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_weight(d: int, word: str, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Given a document and a word in that document,\n",
    "    return the weight for the kth topic\n",
    "    \"\"\"\n",
    "    return p_word_given_topic(word, k) * p_topic_given_document(k, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c424f7e6-fe10-4a70-9633-fa491d8b4b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_new_topic(d: int, word: str) -> int:\n",
    "    return sample_from([topic_weight(d, word, k)\n",
    "                        for k in range(K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2840d17-823a-41bf-9eb1-fd07ed884fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3, 0, 2, 3, 3, 2],\n",
       " [3, 2, 1, 1, 2],\n",
       " [1, 0, 2, 1, 2, 0],\n",
       " [0, 2, 3, 0, 2],\n",
       " [3, 2, 1, 3],\n",
       " [3, 2, 0, 0, 0, 3],\n",
       " [0, 3, 2, 1],\n",
       " [2, 0, 1, 1],\n",
       " [1, 1, 3, 0],\n",
       " [0, 2, 3, 0],\n",
       " [2, 2, 0],\n",
       " [2, 1, 2, 3],\n",
       " [0, 3, 2],\n",
       " [1, 2, 1, 1, 1],\n",
       " [0, 2, 3]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "document_topics = [[random.randrange(K) for word in document]\n",
    "                   for document in documents]\n",
    "document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46412e05-4129-4258-997d-f06d2f765079",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(D):\n",
    "    for word, topic in zip(documents[d], document_topics[d]):\n",
    "        document_topic_counts[d][topic] += 1\n",
    "        topic_word_counts[topic][word] += 1\n",
    "        topic_counts[topic] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a788c86-919a-410c-aea7-cec3438afd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 15, 20, 16]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa644e33-5adf-4eeb-ad7f-77daabc1d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa7f7585-4566-46cf-acc6-bfc3a3854edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2762.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for iter in tqdm.trange(1000):\n",
    "    for d in range(D):\n",
    "        for i, (word, topic) in enumerate(zip(documents[d],\n",
    "                                              document_topics[d])):\n",
    "\n",
    "            # remove this word / topic from the counts\n",
    "            # so that it doesn't influence the weights\n",
    "            document_topic_counts[d][topic] -= 1\n",
    "            topic_word_counts[topic][word] -= 1\n",
    "            topic_counts[topic] -= 1\n",
    "            document_lengths[d] -= 1\n",
    "\n",
    "            # choose a new topic based on the weights\n",
    "            new_topic = choose_new_topic(d, word)\n",
    "            document_topics[d][i] = new_topic\n",
    "\n",
    "            # and now add it back to the counts\n",
    "            document_topic_counts[d][new_topic] += 1\n",
    "            topic_word_counts[new_topic][word] += 1\n",
    "            topic_counts[new_topic] += 1\n",
    "            document_lengths[d] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e283eaf5-9471-415f-abab-2a110f4d9889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'HBase': 1,\n",
       "          'scikit-learn': 0,\n",
       "          'pandas': 0,\n",
       "          'R': 0,\n",
       "          'regression': 0,\n",
       "          'Java': 3,\n",
       "          'C++': 1,\n",
       "          'Haskell': 0,\n",
       "          'statistics': 0,\n",
       "          'artificial intelligence': 0,\n",
       "          'Hadoop': 2,\n",
       "          'Big Data': 3,\n",
       "          'statsmodels': 0,\n",
       "          'libsvm': 0,\n",
       "          'Spark': 1,\n",
       "          'Storm': 1,\n",
       "          'programming languages': 1,\n",
       "          'machine learning': 0,\n",
       "          'MapReduce': 1,\n",
       "          'scipy': 0,\n",
       "          'numpy': 0,\n",
       "          'support vector machines': 0,\n",
       "          'Cassandra': 1,\n",
       "          'deep learning': 1,\n",
       "          'decision trees': 0,\n",
       "          'neural networks': 0,\n",
       "          'databases': 0,\n",
       "          'probability': 0,\n",
       "          'theory': 0,\n",
       "          'NoSQL': 0,\n",
       "          'Mahout': 0,\n",
       "          'mathematics': 0,\n",
       "          'Postgres': 0,\n",
       "          'Python': 0,\n",
       "          'MySQL': 0,\n",
       "          'MongoDB': 0}),\n",
       " Counter({'Cassandra': 1,\n",
       "          'HBase': 2,\n",
       "          'Python': 0,\n",
       "          'numpy': 1,\n",
       "          'decision trees': 1,\n",
       "          'theory': 0,\n",
       "          'Mahout': 0,\n",
       "          'neural networks': 2,\n",
       "          'deep learning': 1,\n",
       "          'databases': 1,\n",
       "          'Postgres': 2,\n",
       "          'MySQL': 1,\n",
       "          'MongoDB': 2,\n",
       "          'probability': 0,\n",
       "          'scikit-learn': 0,\n",
       "          'NoSQL': 1,\n",
       "          'machine learning': 2,\n",
       "          'artificial intelligence': 1,\n",
       "          'Storm': 0,\n",
       "          'Spark': 0,\n",
       "          'pandas': 0,\n",
       "          'support vector machines': 0,\n",
       "          'Java': 0,\n",
       "          'statistics': 0,\n",
       "          'regression': 0,\n",
       "          'libsvm': 0,\n",
       "          'R': 0,\n",
       "          'programming languages': 0,\n",
       "          'Hadoop': 0,\n",
       "          'scipy': 1,\n",
       "          'Haskell': 0,\n",
       "          'Big Data': 0,\n",
       "          'C++': 0,\n",
       "          'MapReduce': 0,\n",
       "          'mathematics': 0,\n",
       "          'statsmodels': 0}),\n",
       " Counter({'Java': 0,\n",
       "          'Cassandra': 0,\n",
       "          'MongoDB': 0,\n",
       "          'Postgres': 0,\n",
       "          'scipy': 0,\n",
       "          'statsmodels': 0,\n",
       "          'Python': 2,\n",
       "          'probability': 0,\n",
       "          'regression': 3,\n",
       "          'R': 2,\n",
       "          'mathematics': 1,\n",
       "          'machine learning': 0,\n",
       "          'statistics': 0,\n",
       "          'C++': 0,\n",
       "          'artificial intelligence': 0,\n",
       "          'HBase': 0,\n",
       "          'NoSQL': 0,\n",
       "          'numpy': 0,\n",
       "          'libsvm': 2,\n",
       "          'theory': 0,\n",
       "          'Hadoop': 0,\n",
       "          'support vector machines': 1,\n",
       "          'Spark': 0,\n",
       "          'Storm': 0,\n",
       "          'Haskell': 1,\n",
       "          'pandas': 0,\n",
       "          'programming languages': 0,\n",
       "          'neural networks': 0,\n",
       "          'scikit-learn': 2,\n",
       "          'Mahout': 1,\n",
       "          'deep learning': 0,\n",
       "          'decision trees': 0,\n",
       "          'Big Data': 0,\n",
       "          'MapReduce': 0,\n",
       "          'databases': 0,\n",
       "          'MySQL': 0}),\n",
       " Counter({'Hadoop': 0,\n",
       "          'Big Data': 0,\n",
       "          'Spark': 0,\n",
       "          'Storm': 0,\n",
       "          'NoSQL': 0,\n",
       "          'statistics': 3,\n",
       "          'machine learning': 0,\n",
       "          'libsvm': 0,\n",
       "          'Python': 2,\n",
       "          'programming languages': 0,\n",
       "          'probability': 3,\n",
       "          'MapReduce': 0,\n",
       "          'R': 2,\n",
       "          'support vector machines': 0,\n",
       "          'decision trees': 0,\n",
       "          'C++': 1,\n",
       "          'deep learning': 0,\n",
       "          'artificial intelligence': 1,\n",
       "          'mathematics': 0,\n",
       "          'theory': 1,\n",
       "          'Haskell': 0,\n",
       "          'HBase': 0,\n",
       "          'Cassandra': 0,\n",
       "          'Java': 0,\n",
       "          'MongoDB': 0,\n",
       "          'Postgres': 0,\n",
       "          'regression': 0,\n",
       "          'scipy': 0,\n",
       "          'Mahout': 0,\n",
       "          'pandas': 2,\n",
       "          'databases': 0,\n",
       "          'MySQL': 0,\n",
       "          'scikit-learn': 0,\n",
       "          'neural networks': 0,\n",
       "          'numpy': 0,\n",
       "          'statsmodels': 2})]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0a3577c6-aed8-4e0c-a0ca-15bef78cf3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Java 3\n",
      "0 Big Data 3\n",
      "0 Hadoop 2\n",
      "0 HBase 1\n",
      "0 C++ 1\n",
      "0 Spark 1\n",
      "0 Storm 1\n",
      "0 programming languages 1\n",
      "0 MapReduce 1\n",
      "0 Cassandra 1\n",
      "0 deep learning 1\n",
      "1 HBase 2\n",
      "1 neural networks 2\n",
      "1 Postgres 2\n",
      "1 MongoDB 2\n",
      "1 machine learning 2\n",
      "1 Cassandra 1\n",
      "1 numpy 1\n",
      "1 decision trees 1\n",
      "1 deep learning 1\n",
      "1 databases 1\n",
      "1 MySQL 1\n",
      "1 NoSQL 1\n",
      "1 artificial intelligence 1\n",
      "1 scipy 1\n",
      "2 regression 3\n",
      "2 Python 2\n",
      "2 R 2\n",
      "2 libsvm 2\n",
      "2 scikit-learn 2\n",
      "2 mathematics 1\n",
      "2 support vector machines 1\n",
      "2 Haskell 1\n",
      "2 Mahout 1\n",
      "3 statistics 3\n",
      "3 probability 3\n",
      "3 Python 2\n",
      "3 R 2\n",
      "3 pandas 2\n",
      "3 statsmodels 2\n",
      "3 C++ 1\n",
      "3 artificial intelligence 1\n",
      "3 theory 1\n"
     ]
    }
   ],
   "source": [
    "for k, word_counts in enumerate(topic_word_counts):\n",
    "    for word, count in word_counts.most_common():\n",
    "        if count > 0:\n",
    "            print(k, word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f0ea29c-be01-429c-982b-ff783e4accd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"Big Data and programming languages\",\n",
    "               \"Python and statistics\",\n",
    "               \"databases\",\n",
    "               \"machine learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c1da5e-b00e-461c-b16b-441b20c16106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63aaf760-7699-4f33-afb3-de5c753012d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hadoop', 'Big Data', 'HBase', 'Java', 'Spark', 'Storm', 'Cassandra']\n",
      "Big Data and programming languages 7\n",
      "\n",
      "['NoSQL', 'MongoDB', 'Cassandra', 'HBase', 'Postgres']\n",
      "Python and statistics 5\n",
      "\n",
      "['Python', 'scikit-learn', 'scipy', 'numpy', 'statsmodels', 'pandas']\n",
      "Python and statistics 2\n",
      "databases 2\n",
      "machine learning 2\n",
      "\n",
      "['R', 'Python', 'statistics', 'regression', 'probability']\n",
      "machine learning 3\n",
      "databases 2\n",
      "\n",
      "['machine learning', 'regression', 'decision trees', 'libsvm']\n",
      "databases 2\n",
      "Python and statistics 2\n",
      "\n",
      "['Python', 'R', 'Java', 'C++', 'Haskell', 'programming languages']\n",
      "databases 3\n",
      "Big Data and programming languages 3\n",
      "\n",
      "['statistics', 'probability', 'mathematics', 'theory']\n",
      "machine learning 3\n",
      "databases 1\n",
      "\n",
      "['machine learning', 'scikit-learn', 'Mahout', 'neural networks']\n",
      "databases 2\n",
      "Python and statistics 2\n",
      "\n",
      "['neural networks', 'deep learning', 'Big Data', 'artificial intelligence']\n",
      "Python and statistics 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['Hadoop', 'Java', 'MapReduce', 'Big Data']\n",
      "Big Data and programming languages 4\n",
      "\n",
      "['statistics', 'R', 'statsmodels']\n",
      "machine learning 3\n",
      "\n",
      "['C++', 'deep learning', 'artificial intelligence', 'probability']\n",
      "machine learning 3\n",
      "Big Data and programming languages 1\n",
      "\n",
      "['pandas', 'R', 'Python']\n",
      "machine learning 3\n",
      "\n",
      "['databases', 'HBase', 'Postgres', 'MySQL', 'MongoDB']\n",
      "Python and statistics 5\n",
      "\n",
      "['libsvm', 'regression', 'support vector machines']\n",
      "databases 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for document, topic_counts in zip(documents, document_topic_counts):\n",
    "    print(document)\n",
    "    for topic, count in topic_counts.most_common():\n",
    "        if count > 0:\n",
    "            print(topic_names[topic], count)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3075a63c-d462-4905-b8c3-8659f0f53e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 3), (0, 0), (3, 0), (1, 0)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9ca26ff-7f28-490a-9896-c7ce762b5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "0 0\n",
      "3 0\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "for topic, count in topic_counts.most_common():\n",
    "    print(topic, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06a6ac4e-8a04-47f5-a9b8-5cdb24b9e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from linear_algebra.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from linear_algebra import dot, Vector\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "adb0d004-764a-418b-92de-3bd3838c660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1: Vector, v2: Vector) -> float:\n",
    "    return dot(v1, v2) / math.sqrt(dot(v1, v1) * dot(v2, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "583c2a7e-35da-40b6-b12c-70d40cf08b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cosine_similarity([1., 1, 1], [2., 2, 2]) == 1, \"same direction\"\n",
    "assert cosine_similarity([-1., -1], [2., 2]) == -1,    \"opposite direction\"\n",
    "assert cosine_similarity([1., 0], [0., 1]) == 0,       \"orthogonal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc577de6-22aa-4d7a-a715-cd3b229450c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"green\", \"blue\", \"yellow\", \"black\", \"\"]\n",
    "nouns = [\"bed\", \"car\", \"boat\", \"cat\"]\n",
    "verbs = [\"is\", \"was\", \"seems\"]\n",
    "adverbs = [\"very\", \"quite\", \"extremely\", \"\"]\n",
    "adjectives = [\"slow\", \"fast\", \"soft\", \"hard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34100297-cd81-4932-a03b-f03db127bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentence() -> str:\n",
    "    return \" \".join([\n",
    "        \"The\",\n",
    "        random.choice(colors),\n",
    "        random.choice(nouns),\n",
    "        random.choice(verbs),\n",
    "        random.choice(adverbs),\n",
    "        random.choice(adjectives),\n",
    "        \".\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1805ea4-2215-405b-baa4-576d3917b2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The  bed was  slow .'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_sentence() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cff5abd-20e1-48a1-96a9-b8adf0677a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SENTENCES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca327e61-9bca-4eae-9f44-7e3333886338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The yellow cat is extremely hard .',\n",
       " 'The yellow boat was extremely fast .',\n",
       " 'The black car was quite slow .',\n",
       " 'The black boat seems quite soft .',\n",
       " 'The red bed seems extremely hard .',\n",
       " 'The black bed was  soft .',\n",
       " 'The black car seems  hard .',\n",
       " 'The black boat is very slow .',\n",
       " 'The  cat seems very hard .',\n",
       " 'The blue car seems extremely slow .',\n",
       " 'The green car is quite hard .',\n",
       " 'The red bed was  slow .',\n",
       " 'The blue boat seems very soft .',\n",
       " 'The black car seems extremely hard .',\n",
       " 'The red cat was quite soft .',\n",
       " 'The green car is very soft .',\n",
       " 'The yellow bed is quite fast .',\n",
       " 'The red bed seems  soft .',\n",
       " 'The black car is  soft .',\n",
       " 'The yellow cat seems extremely slow .',\n",
       " 'The blue bed was extremely fast .',\n",
       " 'The green bed seems extremely slow .',\n",
       " 'The  car was quite soft .',\n",
       " 'The yellow bed is quite fast .',\n",
       " 'The red bed is very fast .',\n",
       " 'The black bed was very soft .',\n",
       " 'The red bed seems very fast .',\n",
       " 'The green bed was quite slow .',\n",
       " 'The  bed seems  slow .',\n",
       " 'The blue bed is very soft .',\n",
       " 'The blue cat is very hard .',\n",
       " 'The red bed seems  fast .',\n",
       " 'The blue boat seems  fast .',\n",
       " 'The  car is quite fast .',\n",
       " 'The blue boat is  fast .',\n",
       " 'The red cat seems  soft .',\n",
       " 'The  boat was extremely fast .',\n",
       " 'The black bed was very soft .',\n",
       " 'The  bed seems extremely fast .',\n",
       " 'The green cat was extremely soft .',\n",
       " 'The black car seems extremely hard .',\n",
       " 'The  cat seems very slow .',\n",
       " 'The black car seems extremely fast .',\n",
       " 'The green car seems  hard .',\n",
       " 'The  cat is  hard .',\n",
       " 'The  bed is  slow .',\n",
       " 'The blue car was  slow .',\n",
       " 'The red cat was extremely hard .',\n",
       " 'The red cat is very fast .',\n",
       " 'The red cat seems  soft .']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "sentences = [make_sentence() for _ in range(NUM_SENTENCES)]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d51164f9-3c18-496e-9303-2bc80fb30c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scratch.deep_learning import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492b693-0849-4e78-a584-cb009bc7e8d6",
   "metadata": {},
   "source": [
    "# the remain of code on the github use deep learning wich it weren't done by author"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
